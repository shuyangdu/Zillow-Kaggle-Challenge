{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter Optimization\n",
    "Wrap __[hyperopt](https://hyperopt.github.io/hyperopt/)__ into **HyperParameterOpt** to do hyper-parameter optimization. Use random search and logged the parameters have been searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from hyperopt import hp, fmin, tpe, Trials, space_eval, STATUS_OK\n",
    "# from schema.columns_added_filled import LABEL_COL, NUMERICAL_COLS, CATEGORICAL_COLS, LOG_COLS\n",
    "from schema.columns_added import LABEL_COL, NUMERICAL_COLS, CATEGORICAL_COLS, LOG_COLS\n",
    "from data_process.data_transform_processor import DataTransformProcessor\n",
    "from models.nn_models.dnn import DNN\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from models.tree_models.lgbm import LGBM\n",
    "from models.hyperparameter_opt import HyperParameterOpt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('/Users/shuyangdu/Desktop/ZillowChallenge/data/df_merged_20171008.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processor_dct = {\n",
    "    'dummy': DataTransformProcessor(\n",
    "    use_dummy=True, use_scale=True,\n",
    "    numerical_cols=NUMERICAL_COLS, \n",
    "    categorical_cols=CATEGORICAL_COLS,\n",
    "    log_cols=LOG_COLS, \n",
    "    label_col=LABEL_COL,\n",
    "),\n",
    "    'tree': DataTransformProcessor(\n",
    "    numerical_cols=NUMERICAL_COLS, \n",
    "    categorical_cols=CATEGORICAL_COLS,\n",
    "    log_cols=LOG_COLS, \n",
    "    label_col=LABEL_COL,\n",
    "),\n",
    "    'dummy_pca': DataTransformProcessor(\n",
    "    use_dummy=True, use_scale=True, use_pca=True,\n",
    "    numerical_cols=NUMERICAL_COLS, \n",
    "    categorical_cols=CATEGORICAL_COLS,\n",
    "    log_cols=LOG_COLS, \n",
    "    label_col=LABEL_COL,\n",
    "),\n",
    "    'tree_pca': DataTransformProcessor(\n",
    "    use_scale=True, use_pca=True,\n",
    "    numerical_cols=NUMERICAL_COLS, \n",
    "    categorical_cols=CATEGORICAL_COLS,\n",
    "    log_cols=LOG_COLS, \n",
    "    label_col=LABEL_COL,\n",
    "),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use all data_processors to pre process to get categorical idx\n",
    "for processor in data_processor_dct.values():\n",
    "    X_all = processor.pre_process(df_all)\n",
    "y_all = df_all['logerror'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search space for DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space_dnn = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -4*np.log(10), -1*np.log(10)),\n",
    "    'reg': hp.loguniform('reg', -4*np.log(10), 1*np.log(10)),\n",
    "    'decay': hp.loguniform('decay', -3*np.log(10), -1*np.log(10)),\n",
    "    'dim_hidden_lst': hp.choice('dim_hidden_lst', [(20,), (40,), (60,), \n",
    "                                                   (20,20), (40,40), (60,60),\n",
    "                                                   (20,20,20), (40,40,40), (60,60,60)]),\n",
    "    'epochs': 5 + hp.randint('epochs', 6),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search space for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space_gbdt = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -2*np.log(10), -1*np.log(10)),  # 1e-2 ~ 1e-1\n",
    "    'n_estimators': 50 * (8 + hp.randint('n_estimators', 5)),  # 400 ~ 600\n",
    "    'num_leaves': 20 * (10 + hp.randint('num_leaves', 11)),  # 200 ~ 400\n",
    "    'lambda_l2': hp.loguniform('lambda_l2', 1*np.log(10), 3*np.log(10)),  # 1e0 ~ 1e3\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.3, 0.8),  #  0.3 ~ 0.8\n",
    "    'bagging_freq': 10 * (2 + hp.randint('bagging_freq', 7)),  # 20 ~ 80\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.7, 1.0),\n",
    "    'max_bin': 40 * (1 + hp.randint('max_bin', 5)),  # 40 ~ 200\n",
    "}\n",
    "\n",
    "space_dart = space_gbdt.copy()\n",
    "space_dart.update({\n",
    "    'drop_rate': hp.uniform('drop_rate', 0.0, 0.5),  #  0.0 ~ 0.5\n",
    "    'skip_drop':hp.uniform('skip_drop', 0.5, 1.0),  #  0.5 ~ 1.0\n",
    "})\n",
    "                              \n",
    "fixed_params_gbdt_l1 = {\n",
    "    'objective': 'regression_l1',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'categorical_feature': data_processor_dct['tree'].categorical_col_idx,\n",
    "}\n",
    "\n",
    "fixed_params_gbdt_l2 = {\n",
    "    'objective': 'regression_l2',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'categorical_feature': data_processor_dct['tree'].categorical_col_idx,\n",
    "}\n",
    "\n",
    "fixed_params_dart_l1 = {\n",
    "    'objective': 'regression_l1',\n",
    "    'boosting_type': 'dart',\n",
    "    'categorical_feature': data_processor_dct['tree'].categorical_col_idx,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search space for Linear Regression ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space_eln = {\n",
    "    'alpha': hp.loguniform('alpha', -2*np.log(10), 2*np.log(10)),\n",
    "    'l1_ratio': hp.uniform('l1_ratio', 0.0, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize for hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_opt = HyperParameterOpt(\n",
    "    model_class=ElasticNet, \n",
    "    data_processor=data_processor_dct['dummy'],                           \n",
    "    search_space=space_eln,\n",
    "    fixed_params={},\n",
    "    max_evals=100,\n",
    "    max_workers=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "Single CV finished\n",
      "CPU times: user 33min 12s, sys: 3min 10s, total: 36min 22s\n",
      "Wall time: 1h 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hyper_opt.optimize(X_all, y_all, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>loss</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018355</td>\n",
       "      <td>0.138619</td>\n",
       "      <td>0.069259</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017625</td>\n",
       "      <td>0.149046</td>\n",
       "      <td>0.069259</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010066</td>\n",
       "      <td>0.237958</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010383</td>\n",
       "      <td>0.252110</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025013</td>\n",
       "      <td>0.073535</td>\n",
       "      <td>0.069268</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.299367</td>\n",
       "      <td>0.069268</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055372</td>\n",
       "      <td>0.061170</td>\n",
       "      <td>0.069271</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.019508</td>\n",
       "      <td>0.091124</td>\n",
       "      <td>0.069271</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.010119</td>\n",
       "      <td>0.346622</td>\n",
       "      <td>0.069274</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.355507</td>\n",
       "      <td>0.069278</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.017893</td>\n",
       "      <td>0.203254</td>\n",
       "      <td>0.069278</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.015475</td>\n",
       "      <td>0.104563</td>\n",
       "      <td>0.069279</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.022698</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.069290</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.342125</td>\n",
       "      <td>0.069299</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.013821</td>\n",
       "      <td>0.057231</td>\n",
       "      <td>0.069303</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.015346</td>\n",
       "      <td>0.287020</td>\n",
       "      <td>0.069311</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.361833</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.014656</td>\n",
       "      <td>0.035686</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.049290</td>\n",
       "      <td>0.104263</td>\n",
       "      <td>0.069340</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.069405</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.100691</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.017326</td>\n",
       "      <td>0.399894</td>\n",
       "      <td>0.069432</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.010195</td>\n",
       "      <td>0.735328</td>\n",
       "      <td>0.069443</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.132716</td>\n",
       "      <td>0.220034</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.154493</td>\n",
       "      <td>0.996111</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.893196</td>\n",
       "      <td>0.396016</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.349123</td>\n",
       "      <td>0.535745</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.609124</td>\n",
       "      <td>0.172219</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.070740</td>\n",
       "      <td>0.147982</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20.948231</td>\n",
       "      <td>0.027799</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.320458</td>\n",
       "      <td>0.538864</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4.869399</td>\n",
       "      <td>0.984569</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.055069</td>\n",
       "      <td>0.417884</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1.555813</td>\n",
       "      <td>0.830950</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>35.729557</td>\n",
       "      <td>0.266045</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.316981</td>\n",
       "      <td>0.219553</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.785823</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>9.996797</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.034986</td>\n",
       "      <td>0.563171</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.171778</td>\n",
       "      <td>0.388153</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.044824</td>\n",
       "      <td>0.292167</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.192959</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.028245</td>\n",
       "      <td>0.328227</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.164987</td>\n",
       "      <td>0.255263</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.468454</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.226866</td>\n",
       "      <td>0.139019</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.033030</td>\n",
       "      <td>0.315943</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.662367</td>\n",
       "      <td>0.685633</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.270190</td>\n",
       "      <td>0.717624</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>23.889233</td>\n",
       "      <td>0.081035</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.685183</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>88.102296</td>\n",
       "      <td>0.429770</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>20.811726</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.201230</td>\n",
       "      <td>0.884936</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>62.217007</td>\n",
       "      <td>0.749065</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>12.486350</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.623717</td>\n",
       "      <td>0.632029</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>90.308291</td>\n",
       "      <td>0.782659</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>88.740536</td>\n",
       "      <td>0.183691</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.458445</td>\n",
       "      <td>0.450842</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        alpha  l1_ratio      loss status\n",
       "0    0.018355  0.138619  0.069259     ok\n",
       "1    0.017625  0.149046  0.069259     ok\n",
       "2    0.010066  0.237958  0.069260     ok\n",
       "3    0.010383  0.252110  0.069260     ok\n",
       "4    0.025013  0.073535  0.069268     ok\n",
       "5    0.010600  0.299367  0.069268     ok\n",
       "6    0.055372  0.061170  0.069271     ok\n",
       "7    0.019508  0.091124  0.069271     ok\n",
       "8    0.010119  0.346622  0.069274     ok\n",
       "9    0.010200  0.355507  0.069278     ok\n",
       "10   0.017893  0.203254  0.069278     ok\n",
       "11   0.015475  0.104563  0.069279     ok\n",
       "12   0.022698  0.042056  0.069290     ok\n",
       "13   0.011952  0.342125  0.069299     ok\n",
       "14   0.013821  0.057231  0.069303     ok\n",
       "15   0.015346  0.287020  0.069311     ok\n",
       "16   0.013036  0.361833  0.069322     ok\n",
       "17   0.014656  0.035686  0.069333     ok\n",
       "18   0.049290  0.104263  0.069340     ok\n",
       "19   0.012325  0.005077  0.069405     ok\n",
       "20   0.100691  0.066015  0.069419     ok\n",
       "21   0.017326  0.399894  0.069432     ok\n",
       "22   0.010195  0.735328  0.069443     ok\n",
       "23   0.132716  0.220034  0.069444     ok\n",
       "24   0.154493  0.996111  0.069444     ok\n",
       "25   0.893196  0.396016  0.069444     ok\n",
       "26   0.349123  0.535745  0.069444     ok\n",
       "27   7.609124  0.172219  0.069444     ok\n",
       "28   0.070740  0.147982  0.069444     ok\n",
       "29  20.948231  0.027799  0.069444     ok\n",
       "..        ...       ...       ...    ...\n",
       "70   2.320458  0.538864  0.069444     ok\n",
       "71   4.869399  0.984569  0.069444     ok\n",
       "72   0.055069  0.417884  0.069444     ok\n",
       "73   1.555813  0.830950  0.069444     ok\n",
       "74  35.729557  0.266045  0.069444     ok\n",
       "75   0.316981  0.219553  0.069444     ok\n",
       "76   0.010801  0.785823  0.069444     ok\n",
       "77   9.996797  0.956820  0.069444     ok\n",
       "78   0.034986  0.563171  0.069444     ok\n",
       "79   0.171778  0.388153  0.069444     ok\n",
       "80   0.044824  0.292167  0.069444     ok\n",
       "81   0.088664  0.192959  0.069444     ok\n",
       "82   0.028245  0.328227  0.069444     ok\n",
       "83   0.164987  0.255263  0.069444     ok\n",
       "84   0.032172  0.468454  0.069444     ok\n",
       "85   0.226866  0.139019  0.069444     ok\n",
       "86   0.033030  0.315943  0.069444     ok\n",
       "87   0.662367  0.685633  0.069444     ok\n",
       "88   0.270190  0.717624  0.069444     ok\n",
       "89  23.889233  0.081035  0.069444     ok\n",
       "90   1.685183  0.874486  0.069444     ok\n",
       "91  88.102296  0.429770  0.069444     ok\n",
       "92  20.811726  0.009675  0.069444     ok\n",
       "93   1.201230  0.884936  0.069444     ok\n",
       "94  62.217007  0.749065  0.069444     ok\n",
       "95  12.486350  0.003564  0.069444     ok\n",
       "96   0.623717  0.632029  0.069444     ok\n",
       "97  90.308291  0.782659  0.069444     ok\n",
       "98  88.740536  0.183691  0.069444     ok\n",
       "99   0.458445  0.450842  0.069444     ok\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_opt.trial_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Save opt log history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_opt.trial_results.to_csv(\n",
    "    '/Users/shuyangdu/Desktop/ZillowChallenge/hyper-parameter-opt/eln_added_features_201701010.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
